# Categorical DQN (C51)

## Overview

C51 extends DQN by modeling the full return distribution instead of just the expected value. By learning a categorical distribution over possible returns, C51 provides richer information about the uncertainty and risk associated with different actions.

## Algorithm Description

C51 represents the return distribution using a fixed set of atoms (discrete values) spanning a range of possible returns. The network outputs probabilities for each atom, creating a categorical distribution over returns.

**Key Components:**

- **Categorical Distribution**: Models returns as a distribution over fixed atoms
- **Distributional Bellman Operator**: Projects target distributions onto support atoms
- **Cross-Entropy Loss**: Trains the network to match target distributions

## Key Papers

- [A Distributional Perspective on Reinforcement Learning](https://arxiv.org/abs/1707.06887) (Bellemare et al., 2017) - C51

## Implementation Details

This Equinox implementation ([`ff_c51.py`](../../../zenoqx/systems/q_learning/ff_c51.py)) features:

- Categorical output head with fixed number of atoms
- Distributional Bellman operator for target computation
- Projection of target distributions onto support
- Cross-entropy loss between predicted and target distributions

### Categorical Network Head

```python
# TODO: Add categorical network architecture
```

### Distributional Bellman Update

```python
# TODO: Add distributional Bellman operator
```

## Related Algorithms

- [DQN](dqn.md) - Base value-based method
- [QR-DQN](qr_dqn.md) - Alternative distributional approach
- [Rainbow](rainbow.md) - Includes C51 as a component
